{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thomas-A1/Convolutional/blob/main/SampleNotebook_ICSDeepLearning_Prosit1_Team5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"CINIC-10 Image Classification.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "m1VyUBs0_ItH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Data Loading"
      ],
      "metadata": {
        "id": "0cGiuO4EzPqa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb3da60a"
      },
      "outputs": [],
      "source": [
        "# --- 1. Install and Import Necessary Packages ---\n",
        "!pip install -q torchsummary\n",
        "!pip install -q tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, datasets, models\n",
        "from torchsummary import summary\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8ac758c"
      },
      "source": [
        "# --- 2. Setup: Connect to Drive and Device ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Figure out Dataset Path Structure (using shortcut) ---\n",
        "\n",
        "drive_data_dir = \"/content/drive/MyDrive/Deep_Learning/prosit_1/cinic-10\" # @param {type:\"string\"}\n",
        "\n",
        "print(f\"Using dataset path from Google Drive shortcut: {drive_data_dir}\")\n",
        "\n",
        "# Verify the path and find the actual data directory if it's in a subfolder\n",
        "contents = os.listdir(drive_data_dir)\n",
        "print(\"Contents of dataset directory:\", contents)\n",
        "\n",
        "final_data_path = drive_data_dir\n",
        "# Look for 'train', 'valid', 'test' subdirectories directly in the shortcut directory\n",
        "if all(os.path.exists(os.path.join(drive_data_dir, split)) for split in ['train', 'valid', 'test']):\n",
        "     print(f\"Found dataset splits directly in the shortcut directory.\")\n",
        "else:\n",
        "    # If not directly there, look for a subfolder containing the splits (like the original download structure)\n",
        "    found_subfolder = False\n",
        "    for item in contents:\n",
        "        item_path = os.path.join(drive_data_dir, item)\n",
        "        if os.path.isdir(item_path) and all(os.path.exists(os.path.join(item_path, split)) for split in ['train', 'valid', 'test']):\n",
        "            final_data_path = item_path\n",
        "            print(f\"Found dataset in subfolder: {item}\")\n",
        "            found_subfolder = True\n",
        "            break\n",
        "    if not found_subfolder:\n",
        "        print(\"Warning: Could not find 'train', 'valid', 'test' subdirectories in the specified path or any immediate subfolder.\")\n",
        "        print(\"Please ensure the shortcut points to the correct location of the extracted CINIC-10 dataset.\")\n",
        "\n",
        "\n",
        "train_dir = os.path.join(final_data_path, 'train')\n",
        "valid_dir = os.path.join(final_data_path, 'valid')\n",
        "test_dir = os.path.join(final_data_path, 'test')\n",
        "\n",
        "print(f\"\\nFinal paths:\")\n",
        "print(f\"Train: {train_dir} - Exists: {os.path.exists(train_dir)}\")\n",
        "print(f\"Valid: {valid_dir} - Exists: {os.path.exists(valid_dir)}\")\n",
        "print(f\"Test: {test_dir} - Exists: {os.path.exists(test_dir)}\")"
      ],
      "metadata": {
        "id": "KmuJgGYOBTjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f37fe50",
        "outputId": "f1ab42da-88c3-4058-e730-5609b7ebf61f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class names: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "Number of classes: 10\n",
            "\n",
            "Using manually provided original dataset sizes.\n",
            "\n",
            "Target total subset size: 2700\n",
            "Target new split sizes: Train: 1889, Valid: 540, Test: 271\n",
            "\n",
            "Percentage to sample from original splits:\n",
            "From Original Train: 2.10%\n",
            "From Original Valid: 0.60%\n",
            "From Original Test: 0.30%\n",
            "Listing files in train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sampling 2.10% from train: 100%|██████████| 10/10 [00:38<00:00,  3.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing files in valid...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Sampling 0.60% from valid: 100%|██████████| 10/10 [00:41<00:00,  4.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing files in test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Sampling 0.30% from test: 100%|██████████| 10/10 [00:35<00:00,  3.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Actual new split sizes after sampling:\n",
            "Train: 1881\n",
            "Valid: 540\n",
            "Test: 270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Creating dataset samples: 100%|██████████| 1881/1881 [00:00<00:00, 346851.57it/s]\n",
            "Creating dataset samples: 100%|██████████| 540/540 [00:00<00:00, 317127.44it/s]\n",
            "Creating dataset samples: 100%|██████████| 270/270 [00:00<00:00, 92062.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train dataset size: 1881\n",
            "Validation dataset size: 540\n",
            "Test dataset size: 270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# --- 4a. Subset Data from Original Splits with Custom Proportions ---\n",
        "\n",
        "total_data_percentage = 1 # @param {type:\"number\"}\n",
        "\n",
        "if total_data_percentage < 0 or total_data_percentage > 100:\n",
        "    print(\"Warning: Total data percentage should be between 0 and 100. Using 100%.\", flush=True)\n",
        "    total_data_percentage = 100\n",
        "\n",
        "# Define the NEW split percentages for the SELECTED SUBSET\n",
        "# These percentages will determine the proportion of images taken from the *original* splits\n",
        "# to form the new train, valid, and test sets.\n",
        "train_split_percentage_subset = 70 # @param {type:\"number\"}\n",
        "valid_split_percentage_subset = 20 # @param {type:\"number\"}\n",
        "test_split_percentage_subset = 10 # @param {type:\"number\"}\n",
        "\n",
        "# Optional: Provide original dataset split sizes to skip counting\n",
        "original_train_size_manual = 90000 # @param {type:\"number\"}\n",
        "original_valid_size_manual = 90000 # @param {type:\"number\"}\n",
        "original_test_size_manual = 90000 # @param {type:\"number\"}\n",
        "\n",
        "\n",
        "# Check if the new subset percentages sum to 100\n",
        "if train_split_percentage_subset + valid_split_percentage_subset + test_split_percentage_subset != 100:\n",
        "    print(\"Warning: The new subset split percentages do not sum to 100. Adjusting test percentage for subset.\", flush=True)\n",
        "    test_split_percentage_subset = 100 - train_split_percentage_subset - valid_split_percentage_subset\n",
        "    print(f\"Adjusted subset splits: Train: {train_split_percentage_subset}%, Valid: {valid_split_percentage_subset}%, Test: {test_split_percentage_subset}%\", flush=True)\n",
        "\n",
        "\n",
        "# Get class names\n",
        "# Assuming classes are the subdirectory names in the original train directory\n",
        "class_names = sorted([d.name for d in os.scandir(train_dir) if d.is_dir()])\n",
        "num_classes = len(class_names)\n",
        "print(f\"\\nClass names: {class_names}\", flush=True)\n",
        "print(f\"Number of classes: {num_classes}\", flush=True)\n",
        "\n",
        "# Function to get a subset of image paths from a single directory while maintaining class distribution\n",
        "def get_subset_paths_from_dir(data_dir, classes, percentage_of_dir):\n",
        "    image_paths_from_dir = []\n",
        "    print(f\"Listing files in {os.path.basename(data_dir)}...\", flush=True) # Added print statement\n",
        "    for class_name in tqdm(classes, desc=f\"Sampling {percentage_of_dir:.2f}% from {os.path.basename(data_dir)}\", leave=True): # Changed leave=False to leave=True\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        if os.path.exists(class_dir):\n",
        "            image_files = [os.path.join(class_dir, f) for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n",
        "            num_samples_in_class = len(image_files)\n",
        "            subset_size_class = int(num_samples_in_class * (percentage_of_dir / 100))\n",
        "            # Randomly sample indices instead of shuffling the whole list\n",
        "            sampled_indices = np.random.choice(num_samples_in_class, size=subset_size_class, replace=False)\n",
        "            image_paths_from_dir.extend([image_files[i] for i in sampled_indices])\n",
        "    return image_paths_from_dir\n",
        "\n",
        "# Calculate the total number of images in the original dataset\n",
        "# Use manual sizes if provided and positive, otherwise count\n",
        "if original_train_size_manual > 0 and original_valid_size_manual > 0 and original_test_size_manual > 0:\n",
        "    original_train_size = original_train_size_manual\n",
        "    original_valid_size = original_valid_size_manual\n",
        "    original_test_size = original_test_size_manual\n",
        "    print(\"\\nUsing manually provided original dataset sizes.\", flush=True)\n",
        "else:\n",
        "    print(\"Calculating total number of original images...\", flush=True) # Added print statement\n",
        "    original_train_size = sum(len(os.listdir(os.path.join(train_dir, c))) for c in class_names if os.path.exists(os.path.join(train_dir, c)))\n",
        "    original_valid_size = sum(len(os.listdir(os.path.join(valid_dir, c))) for c in class_names if os.path.exists(os.path.join(valid_dir, c)))\n",
        "    original_test_size = sum(len(os.listdir(os.path.join(test_dir, c))) for c in class_names if os.path.exists(os.path.join(test_dir, c)))\n",
        "    print(\"\\nCalculated original dataset sizes.\", flush=True)\n",
        "\n",
        "\n",
        "total_original_images = original_train_size + original_valid_size + original_test_size\n",
        "\n",
        "\n",
        "# Calculate the target total subset size\n",
        "target_subset_size = int(total_original_images * (total_data_percentage / 100))\n",
        "\n",
        "# Distribute the target subset size according to the desired new split percentages\n",
        "target_train_size = int(target_subset_size * (train_split_percentage_subset / 100))\n",
        "target_valid_size = int(target_subset_size * (valid_split_percentage_subset / 100))\n",
        "target_test_size = target_subset_size - target_train_size - target_valid_size # Ensure sum is exact\n",
        "\n",
        "print(f\"\\nTarget total subset size: {target_subset_size}\", flush=True)\n",
        "print(f\"Target new split sizes: Train: {target_train_size}, Valid: {target_valid_size}, Test: {target_test_size}\", flush=True)\n",
        "\n",
        "\n",
        "# To get the desired number of images for the new splits from their ORIGINAL directories,\n",
        "# we need to calculate what percentage of the ORIGINAL split size corresponds to the TARGET new split size.\n",
        "\n",
        "# Calculate the percentage needed from each ORIGINAL split to meet the TARGET new split size\n",
        "# Handle division by zero if original split is empty\n",
        "percentage_from_original_train = (target_train_size / original_train_size) * 100 if original_train_size > 0 else 0\n",
        "percentage_from_original_valid = (target_valid_size / original_valid_size) * 100 if original_valid_size > 0 else 0\n",
        "percentage_from_original_test = (target_test_size / original_test_size) * 100 if original_test_size > 0 else 0\n",
        "\n",
        "print(f\"\\nPercentage to sample from original splits:\", flush=True)\n",
        "print(f\"From Original Train: {percentage_from_original_train:.2f}%\", flush=True)\n",
        "print(f\"From Original Valid: {percentage_from_original_valid:.2f}%\", flush=True)\n",
        "print(f\"From Original Test: {percentage_from_original_test:.2f}%\", flush=True)\n",
        "\n",
        "\n",
        "# Get subset of image paths from original directories using the calculated percentages\n",
        "# Use tqdm for progress bars\n",
        "new_train_paths = get_subset_paths_from_dir(train_dir, class_names, percentage_from_original_train)\n",
        "new_valid_paths = get_subset_paths_from_dir(valid_dir, class_names, percentage_from_original_valid)\n",
        "new_test_paths = get_subset_paths_from_dir(test_dir, class_names, percentage_from_original_test)\n",
        "\n",
        "print(f\"\\nActual new split sizes after sampling:\", flush=True)\n",
        "print(f\"Train: {len(new_train_paths)}\", flush=True)\n",
        "print(f\"Valid: {len(new_valid_paths)}\", flush=True)\n",
        "print(f\"Test: {len(new_test_paths)}\", flush=True)\n",
        "\n",
        "\n",
        "# Custom Dataset class to load from a list of file paths (same as before)\n",
        "class ListDataset(Dataset):\n",
        "    def __init__(self, image_paths, class_names, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "        # Create a mapping from class name to index\n",
        "        self.class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "        self.samples = self._get_samples()\n",
        "\n",
        "    def _get_samples(self):\n",
        "        samples = []\n",
        "        for img_path in tqdm(self.image_paths, desc=\"Creating dataset samples\", leave=True): # Changed leave=False to leave=True\n",
        "            # Extract class name from path (assuming path structure is data_dir/class_name/image.jpg)\n",
        "            class_name = os.path.basename(os.path.dirname(img_path))\n",
        "            if class_name in self.class_to_idx:\n",
        "                target = self.class_to_idx[class_name]\n",
        "                samples.append((img_path, target))\n",
        "        return samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, target = self.samples[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, target\n",
        "\n",
        "# Create datasets using the new subset paths\n",
        "# Transformations will be applied in the next cell\n",
        "train_dataset = ListDataset(new_train_paths, class_names, transform=None)\n",
        "val_dataset = ListDataset(new_valid_paths, class_names, transform=None)\n",
        "test_dataset = ListDataset(new_test_paths, class_names, transform=None)\n",
        "\n",
        "print(f\"\\nTrain dataset size: {len(train_dataset)}\", flush=True)\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\", flush=True)\n",
        "print(f\"Test dataset size: {len(test_dataset)}\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "910f425a",
        "outputId": "3f8d01e1-2868-44a5-8bba-4d8f08ee9595"
      },
      "source": [
        "# --- 4b. Preprocessing and DataLoader Creation ---\n",
        "\n",
        "# Define transformations with data augmentation for training\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Simpler transformations for validation and testing\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Apply transformations to the datasets\n",
        "train_dataset.transform = train_transform\n",
        "val_dataset.transform = test_transform\n",
        "test_dataset.transform = test_transform\n",
        "\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"\\nTrain loader size: {len(train_loader.dataset)}\")\n",
        "print(f\"Validation loader size: {len(val_loader.dataset)}\")\n",
        "print(f\"Test loader size: {len(test_loader.dataset)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loader size: 900\n",
            "Validation loader size: 900\n",
            "Test loader size: 794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DNN"
      ],
      "metadata": {
        "id": "Nk7ygWWzy-S4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2544c267"
      },
      "source": [
        "# --- 5. Define the Deep Feeedforward Neural Network (DNN) Model ---\n",
        "class FeedforwardModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(FeedforwardModel, self).__init__()\n",
        "        # Assuming input image size is 3x32x32\n",
        "        self.fc1 = nn.Linear(3 * 32 * 32, 512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.fc4 = nn.Linear(128, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input image\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.bn3(self.fc3(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "model = FeedforwardModel(num_classes).to(device)\n",
        "print(model)\n",
        "\n",
        "# Display model architecture - note: summary might not display details for flattened input\n",
        "# You might need to adjust summary usage or omit it for clarity with flattened input\n",
        "try:\n",
        "    summary(model, (3, 32, 32))\n",
        "except Exception as e:\n",
        "    print(f\"Could not display summary for Feedforward model: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6424c34a"
      },
      "source": [
        "# --- 6. Define Loss Function and Optimizer ---\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e45c559b",
        "outputId": "e51f5e03-cbc4-4791-bc27-10923cf43a4e"
      },
      "source": [
        "best_model_save_path = \"/content/drive/MyDrive/Deep_Learning/prosit_1/best_cinic10_model.pth\" # @param {type:\"string\"}\n",
        "\n",
        "print(f\"Best model will be saved to: {best_model_save_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model will be saved to: /content/drive/MyDrive/Deep_Learning/prosit_1/best_cinic10_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5dd3bc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1634169-264b-4f60-86e3-8ca95255a7cf"
      },
      "source": [
        "# --- 7. Train the Model ---\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25, save_path='/content/best_model.pth'):\n",
        "    train_loss_history = []\n",
        "    val_accuracy_history = []\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Wrap train_loader with tqdm for progress bar\n",
        "        train_loader_tqdm = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]', leave=False)\n",
        "        for images, labels in train_loader_tqdm:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            train_loader_tqdm.set_postfix({'loss': running_loss / ((train_loader_tqdm.n + 1) * images.size(0))})\n",
        "\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        train_loss_history.append(epoch_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Wrap val_loader with tqdm for progress bar\n",
        "        val_loader_tqdm = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Valid]', leave=False)\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader_tqdm:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_val_accuracy = 100 * correct / total\n",
        "        val_accuracy_history.append(epoch_val_accuracy)\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step(epoch_val_accuracy)\n",
        "\n",
        "        # Save best model\n",
        "        if epoch_val_accuracy > best_accuracy:\n",
        "            best_accuracy = epoch_val_accuracy\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"Saved best model with accuracy {best_accuracy:.2f}% to {save_path}\")\n",
        "\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "              f'Loss: {epoch_loss:.4f}, '\n",
        "              f'Val Accuracy: {epoch_val_accuracy:.2f}%')\n",
        "\n",
        "    return train_loss_history, val_accuracy_history\n",
        "\n",
        "print(\"Starting training...\")\n",
        "# Pass the save path to the training function\n",
        "try:\n",
        "    best_model_save_path\n",
        "except NameError:\n",
        "    best_model_save_path = '/content/best_model.pth' # Default save path if not defined\n",
        "\n",
        "train_loss_history, val_accuracy_history = train_model(\n",
        "    model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30, save_path=best_model_save_path\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30 [Valid]:   0%|          | 0/8 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "997f7cab-ebe9-43df-c005-0cbc12ae725a",
        "id": "D5S9_COpSFL6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded best model for testing.\n",
            "\n",
            "Final Test Accuracy: 24.56%\n"
          ]
        }
      ],
      "source": [
        "# --- 8. Evaluate the Model on Test Set ---\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Wrap test_loader with tqdm for progress bar\n",
        "    test_loader_tqdm = tqdm(test_loader, desc='Evaluating Model', leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader_tqdm:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return all_preds, all_labels\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(best_model_save_path))\n",
        "print(\"Loaded best model for testing.\")\n",
        "\n",
        "# Get predictions\n",
        "test_preds, test_labels = evaluate_model(model, test_loader)\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy = 100 * np.sum(np.array(test_preds) == np.array(test_labels)) / len(test_labels)\n",
        "print(f'\\nFinal Test Accuracy: {test_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0403ba24"
      },
      "source": [
        "# --- 9. Comprehensive Evaluation ---\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_labels, test_preds, target_names=class_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b49bb06"
      },
      "source": [
        "# --- 10. Demonstration: Test on Individual Images ---\n",
        "def predict_image(model, image_path, transform, class_names, device):\n",
        "    \"\"\"Predict the class of a single image\"\"\"\n",
        "    model.eval()\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    # Apply transformations\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "\n",
        "    # Display image\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title('Input Image')\n",
        "\n",
        "    # Display predictions\n",
        "    plt.subplot(1, 2, 2)\n",
        "    y_pos = np.arange(5)\n",
        "    plt.barh(y_pos, top5_prob[0].cpu().numpy(), align='center')\n",
        "    plt.yticks(y_pos, [class_names[i] for i in top5_catid[0].cpu().numpy()])\n",
        "    plt.xlabel('Probability')\n",
        "    plt.title('Top 5 Predictions')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Top 5 Predictions:\")\n",
        "    for i in range(5):\n",
        "        print(f\"{i+1}. {class_names[top5_catid[0][i].item()]}: {top5_prob[0][i].item()*100:.2f}%\")\n",
        "\n",
        "# Test on a few sample images from the test set\n",
        "def test_sample_images(model, test_loader, class_names, num_samples=5):\n",
        "    \"\"\"Test the model on sample images from the test set\"\"\"\n",
        "    model.eval()\n",
        "    data_iter = iter(test_loader)\n",
        "    images, labels = next(data_iter)\n",
        "\n",
        "    for i in range(min(num_samples, len(images))):\n",
        "        image = images[i]\n",
        "        label = labels[i]\n",
        "\n",
        "        # Denormalize for display\n",
        "        image_denorm = image * 0.5 + 0.5\n",
        "        image_denorm = image_denorm.numpy().transpose((1, 2, 0))\n",
        "\n",
        "        # Predict\n",
        "        with torch.no_grad():\n",
        "            output = model(image.unsqueeze(0).to(device))\n",
        "            probabilities = F.softmax(output, dim=1)\n",
        "            _, predicted = torch.max(output, 1)\n",
        "\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(image_denorm)\n",
        "        plt.title(f'True: {class_names[label]}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "        y_pos = np.arange(5)\n",
        "        plt.barh(y_pos, top5_prob[0].cpu().numpy(), align='center')\n",
        "        plt.yticks(y_pos, [class_names[i] for i in top5_catid[0].cpu().numpy()])\n",
        "        plt.xlabel('Probability')\n",
        "        plt.title(f'Predicted: {class_names[predicted.item()]}')\n",
        "        plt.gca().invert_yaxis()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "print(\"Testing on sample images from test set...\")\n",
        "test_sample_images(model, test_loader, class_names, num_samples=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2d24259"
      },
      "source": [
        "# --- 11. Save the Final Model ---\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'class_names': class_names,\n",
        "    'test_accuracy': test_accuracy\n",
        "}, '/content/drive/MyDrive/cinic10_cnn_model.pth')\n",
        "\n",
        "print(\"Model saved to Google Drive: /content/drive/MyDrive/cinic10_cnn_model.pth\")\n",
        "print(\"Implementation complete! The system is ready for demonstration.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "d3LsvVhXoLNY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "073f353d",
        "outputId": "ebbcb5b3-2fbc-435e-83a3-cc680aaebd7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# --- 5. Define the Convolutional Neural Network (CNN) Model ---\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Calculate flattened size after convolutions and pooling\n",
        "        # Assuming input size is 3x32x32\n",
        "        self._to_linear = None\n",
        "        self._get_conv_output_size()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.bn5 = nn.BatchNorm1d(512)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _get_conv_output_size(self):\n",
        "        # Helper function to calculate the output size of the convolutional layers\n",
        "        # Pass a dummy tensor through the conv layers\n",
        "        with torch.no_grad():\n",
        "            x = torch.randn(1, 3, 32, 32)\n",
        "            x = self.pool(F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x)))))))\n",
        "            x = self.pool2(F.relu(self.bn4(self.conv4(F.relu(self.bn3(self.conv3(x)))))))\n",
        "            self._to_linear = x.view(x.size(0), -1).size(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x)))))))\n",
        "        x = self.pool2(F.relu(self.bn4(self.conv4(F.relu(self.bn3(self.conv3(x)))))))\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = F.relu(self.bn5(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "model_cnn = CNNModel(num_classes).to(device)\n",
        "print(model_cnn)\n",
        "\n",
        "# Display model architecture summary\n",
        "try:\n",
        "    summary(model_cnn, (3, 32, 32))\n",
        "except Exception as e:\n",
        "    print(f\"Could not display summary for CNN model: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNNModel(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=16384, out_features=512, bias=True)\n",
            "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "            Conv2d-3           [-1, 64, 32, 32]          18,496\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "         MaxPool2d-5           [-1, 64, 16, 16]               0\n",
            "            Conv2d-6          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-7          [-1, 128, 16, 16]             256\n",
            "            Conv2d-8          [-1, 256, 16, 16]         295,168\n",
            "       BatchNorm2d-9          [-1, 256, 16, 16]             512\n",
            "        MaxPool2d-10            [-1, 256, 8, 8]               0\n",
            "           Linear-11                  [-1, 512]       8,389,120\n",
            "      BatchNorm1d-12                  [-1, 512]           1,024\n",
            "          Dropout-13                  [-1, 512]               0\n",
            "           Linear-14                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 8,784,650\n",
            "Trainable params: 8,784,650\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.26\n",
            "Params size (MB): 33.51\n",
            "Estimated Total Size (MB): 36.78\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b34c39b",
        "outputId": "cd155990-48f4-40ea-aba8-f04da3f9e1b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# --- 6. Define Loss Function and Optimizer for CNN ---\n",
        "criterion_cnn = nn.CrossEntropyLoss()\n",
        "# Using Adam optimizer for CNN\n",
        "optimizer_cnn = optim.Adam(model_cnn.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "scheduler_cnn = optim.lr_scheduler.ReduceLROnPlateau(optimizer_cnn, mode='max', factor=0.5, patience=3)\n",
        "\n",
        "print(\"CNN Loss function and optimizer defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Loss function and optimizer defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5d9239d",
        "outputId": "04fc30a1-4cad-4e47-c817-9d1213a367d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# --- Define Model Save Path in Google Drive for CNN ---\n",
        "base_model_save_path_cnn = \"/content/drive/MyDrive/Deep_Learning/prosit_1/cinic-10_cnn\" # @param {type:\"string\"}\n",
        "\n",
        "# Generate a descriptor based on hyperparameters\n",
        "try:\n",
        "    data_percentage_descriptor = f\"data{total_data_percentage}pct\"\n",
        "except NameError:\n",
        "    data_percentage_descriptor = \"data100pct\" # Default if total_data_percentage is not defined\n",
        "\n",
        "# Get the current learning rate from the optimizer\n",
        "try:\n",
        "    current_lr_cnn = optimizer_cnn.param_groups[0]['lr']\n",
        "    lr_descriptor_cnn = f\"lr{current_lr_cnn}\".replace('.', '_') # Replace . with _ for filename\n",
        "except NameError:\n",
        "    lr_descriptor_cnn = \"lr_N_A\" # Default if optimizer_cnn is not defined\n",
        "\n",
        "best_model_save_path_cnn = f\"{base_model_save_path_cnn}_{data_percentage_descriptor}_{lr_descriptor_cnn}.pth\"\n",
        "\n",
        "print(f\"Best CNN model will be saved to: {best_model_save_path_cnn}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best CNN model will be saved to: /content/drive/MyDrive/Deep_Learning/prosit_1/cinic-10_cnn_data1pct_lr0_01.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32cc6b2a",
        "outputId": "fe5fd167-06d9-49d8-b155-a828fab4e662",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# --- 7. Train the CNN Model ---\n",
        "def train_model_cnn(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25, save_path='/content/best_cnn_model.pth'):\n",
        "    train_loss_history = []\n",
        "    val_accuracy_history = []\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        train_loader_tqdm = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train CNN]', leave=False)\n",
        "        for images, labels in train_loader_tqdm:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            train_loader_tqdm.set_postfix({'loss': running_loss / ((train_loader_tqdm.n + 1) * images.size(0))})\n",
        "\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        train_loss_history.append(epoch_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        val_loader_tqdm = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Valid CNN]', leave=False)\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader_tqdm:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_val_accuracy = 100 * correct / total\n",
        "        val_accuracy_history.append(epoch_val_accuracy)\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step(epoch_val_accuracy)\n",
        "\n",
        "        # Save best model\n",
        "        if epoch_val_accuracy > best_accuracy:\n",
        "            best_accuracy = epoch_val_accuracy\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"Saved best CNN model with accuracy {best_accuracy:.2f}% to {save_path}\")\n",
        "\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "              f'Loss: {epoch_loss:.4f}, '\n",
        "              f'Val Accuracy: {epoch_val_accuracy:.2f}%')\n",
        "\n",
        "    return train_loss_history, val_accuracy_history\n",
        "\n",
        "print(\"Starting CNN training...\")\n",
        "# Pass the save path to the training function\n",
        "try:\n",
        "    best_model_save_path_cnn\n",
        "except NameError:\n",
        "    best_model_save_path_cnn = '/content/best_cnn_model.pth' # Default save path if not defined\n",
        "\n",
        "train_loss_history_cnn, val_accuracy_history_cnn = train_model_cnn(\n",
        "    model_cnn, train_loader, val_loader, criterion_cnn, optimizer_cnn, scheduler_cnn, num_epochs=30, save_path=best_model_save_path_cnn\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting CNN training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30 [Valid CNN]:  40%|████      | 2/5 [01:31<01:53, 37.92s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dad40c8"
      },
      "source": [
        "# --- 8. Evaluate the CNN Model on Test Set ---\n",
        "def evaluate_model_cnn(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    test_loader_tqdm = tqdm(test_loader, desc='Evaluating CNN Model', leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader_tqdm:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return all_preds, all_labels\n",
        "\n",
        "# Load best model\n",
        "model_cnn.load_state_dict(torch.load(best_model_save_path_cnn))\n",
        "print(\"Loaded best CNN model for testing.\")\n",
        "\n",
        "# Get predictions\n",
        "test_preds_cnn, test_labels_cnn = evaluate_model_cnn(model_cnn, test_loader)\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy_cnn = 100 * np.sum(np.array(test_preds_cnn) == np.array(test_labels_cnn)) / len(test_labels_cnn)\n",
        "print(f'\\nFinal CNN Test Accuracy: {test_accuracy_cnn:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a83be0a9"
      },
      "source": [
        "# --- Collect and Store Experiment Data for CNN ---\n",
        "import datetime\n",
        "\n",
        "# Get hyperparameters (assuming they are defined in previous cells)\n",
        "try:\n",
        "    current_lr_cnn = optimizer_cnn.param_groups[0]['lr']\n",
        "except NameError:\n",
        "    current_lr_cnn = 'N/A' # Default if optimizer_cnn is not defined\n",
        "\n",
        "try:\n",
        "    current_weight_decay_cnn = optimizer_cnn.param_groups[0]['weight_decay']\n",
        "except NameError:\n",
        "    current_weight_decay_cnn = 'N/A' # Default if optimizer_cnn is not defined\n",
        "\n",
        "try:\n",
        "    current_batch_size_cnn = batch_size # Use the same batch_size as defined earlier\n",
        "except NameError:\n",
        "    current_batch_size_cnn = 'N/A' # Default if batch_size is not defined\n",
        "\n",
        "try:\n",
        "    # Note: num_epochs is passed to the train_model_cnn function\n",
        "    current_num_epochs_cnn = 30 # Assuming 30 epochs from the train_model_cnn call\n",
        "except NameError:\n",
        "     current_num_epochs_cnn = 'N/A' # Default if not tracked\n",
        "\n",
        "try:\n",
        "    current_data_percentage = total_data_percentage # Use the same data percentage as defined earlier\n",
        "except NameError:\n",
        "    current_data_percentage = 100 # Default if total_data_percentage not defined\n",
        "\n",
        "\n",
        "# Define the path to save the experiment results table in Google Drive\n",
        "# Use a different file name or append to the existing one\n",
        "experiment_table_path_cnn = \"/content/drive/MyDrive/cinic10_experiment_results_cnn.csv\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "# Load existing experiment results if the file exists, otherwise create a new DataFrame\n",
        "if os.path.exists(experiment_table_path_cnn):\n",
        "    experiment_results_df_cnn = pd.read_csv(experiment_table_path_cnn)\n",
        "    print(f\"\\nLoaded existing CNN experiment results from: {experiment_table_path_cnn}\")\n",
        "else:\n",
        "    experiment_results_df_cnn = pd.DataFrame(columns=[\n",
        "        'Timestamp',\n",
        "        'Model Type', # Added Model Type column\n",
        "        'Data Percentage',\n",
        "        'Test Accuracy (%)',\n",
        "        'Model Save Path',\n",
        "        'Learning Rate',\n",
        "        'Weight Decay',\n",
        "        'Batch Size',\n",
        "        'Num Epochs'\n",
        "    ])\n",
        "    print(\"\\nCreated a new CNN experiment results table.\")\n",
        "\n",
        "# Create a new row for the experiment results\n",
        "new_row_cnn = {\n",
        "    'Timestamp': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    'Model Type': 'CNN', # Specify model type\n",
        "    'Data Percentage': current_data_percentage,\n",
        "    'Test Accuracy (%)': test_accuracy_cnn,\n",
        "    'Model Save Path': best_model_save_path_cnn,\n",
        "    'Learning Rate': current_lr_cnn,\n",
        "    'Weight Decay': current_weight_decay_cnn,\n",
        "    'Batch Size': current_batch_size_cnn,\n",
        "    'Num Epochs': current_num_epochs_cnn\n",
        "}\n",
        "\n",
        "# Append the new row to the DataFrame\n",
        "experiment_results_df_cnn = pd.concat([experiment_results_df_cnn, pd.DataFrame([new_row_cnn])], ignore_index=True)\n",
        "\n",
        "# Display the updated table\n",
        "print(\"\\nUpdated CNN Experiment Results Table:\")\n",
        "display(experiment_results_df_cnn)\n",
        "\n",
        "# Optionally save the updated table\n",
        "try:\n",
        "    experiment_table_path_cnn\n",
        "    experiment_results_df_cnn.to_csv(experiment_table_path_cnn, index=False)\n",
        "    print(f\"CNN experiment results table saved to: {experiment_table_path_cnn}\")\n",
        "except NameError:\n",
        "    print(\"Warning: experiment_table_path_cnn not defined. Skipping saving the CNN results table.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9ebd13f"
      },
      "source": [
        "# --- 9. Comprehensive Evaluation for CNN ---\n",
        "# Classification Report\n",
        "print(\"\\nCNN Classification Report:\")\n",
        "print(classification_report(test_labels_cnn, test_preds_cnn, target_names=class_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "cm_cnn = confusion_matrix(test_labels_cnn, test_preds_cnn)\n",
        "sns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('CNN Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 10. Demonstration: Test on Individual Images for CNN ---\n",
        "print(\"\\nTesting CNN on sample images from test set...\")\n",
        "# Reuse the test_sample_images function, it's general enough\n",
        "test_sample_images(model_cnn, test_loader, class_names, num_samples=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "011c3f3d"
      },
      "source": [
        "# --- 11. Save the Final CNN Model ---\n",
        "# Use the best_model_save_path_cnn defined earlier\n",
        "try:\n",
        "    final_model_save_path_cnn = best_model_save_path_cnn\n",
        "except NameError:\n",
        "    final_model_save_path_cnn = '/content/drive/MyDrive/cinic10_final_cnn_model.pth'\n",
        "    print(f\"Warning: best_model_save_path_cnn not defined, saving to default path: {final_model_save_path_cnn}\")\n",
        "\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': model_cnn.state_dict(),\n",
        "    'class_names': class_names,\n",
        "    'test_accuracy': test_accuracy_cnn # Use the CNN test accuracy\n",
        "}, final_model_save_path_cnn)\n",
        "\n",
        "print(f\"\\nCNN Model saved to Google Drive: {final_model_save_path_cnn}\")\n",
        "print(\"CNN implementation complete! The system is ready for demonstration.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}